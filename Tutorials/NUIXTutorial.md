# NUIX-Studio Setup

Firstly, run Main scene.
### 1. Currently, there are four different environments to choose from. To select the environment just click on the button.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-1.png)

### 2. You can then come back to the Main environment.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-3.png)

### 3. Next, there are three gestures to use for performing actions. However, you can create and use your own gestures, which we will talk about later.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-4.png)

### 4. The gestures use Mixed Reality Toolkit for retrieving Hands Position.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-5.png)

### 5. Another NUIX-Studio feature is Speech Recognition service. User creates a list of actions for each of the words needed to be recognized (for example, play, pause, read news, etc), and once the word is said, the action will be performed.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-6.png)

### 6. On the dock positions you can find several objects, which can be used as "blocks" in your smart device prototypes. The first one is Weight scaler - it is a flat surface, which is sensible to the weight of Rigidbody objects laying on it. If the weight exceeds the required value - a specified action is  performed.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-7.png)

### 7. Contact sensors are usually used for Sensing door open/close, or for activation when an object is close another to another object (for example, when a user is close to TV). They can simulate NFC, GPS and other technologies.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-8.png)

### 8. A virtual camera is attached to a sportcam, and the image is shown on a monitor. Virtual cameras can be used to simulate real-world cameras, as well as register presence of the gameobjects in the camera view.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-9.png)

### 9. Users can build their devices from Interactables taken from Mixed Reality Toolkit.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-10.png)

### 10. The most useful are buttons, switches, pinchsliders. They are located at Assets/MRTK/Features/UX/Interactable/Prefabs. To use them, just simply drag them onto the scene.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-11.png)

### 11. I have also uploaded some of the virtual devices most freqesntly asked to share, including: Security camera, Router, Smart bracelet, Smart Speaker, Smartphone and a lamp.
![](https://github.com/FedorIvachev/IoThingsLab-ReadmeFiles/blob/master/Tutorials/NUIX-Tutorial-Pictures/NUIX-Tutorial-12.png)

The second tutorial can be found [here]().
